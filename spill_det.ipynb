{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# DPT imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import util.io\n",
    "from torchvision.transforms import Compose\n",
    "from dpt.models import DPTSegmentationModel\n",
    "from dpt.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "# Classifier imports\n",
    "from tensorflow.keras.applications import * #Efficient Net included here\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "\n",
    "conv_base = EfficientNetB0(weights=\"efficientnetb0_notop.h5\", include_top=False, input_shape=(height,width,3))\n",
    "spill_classifier = models.Sequential()\n",
    "spill_classifier.add(conv_base)\n",
    "spill_classifier.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "#avoid overfitting\n",
    "#model.add(layers.Dropout(rate=0.2, name=\"dropout_out\"))\n",
    "# Set NUMBER_OF_CLASSES to the number of your final predictions.\n",
    "spill_classifier.add(layers.Dense(2, activation=\"softmax\", name=\"fc_out\"))\n",
    "spill_classifier.load_weights(\"model_best_weights.h5\")\n",
    "#spill_classifier = EfficientNetB0(weights=\"model_best_weights.h5\", include_top=False, input_shape=(height,width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidate_spill_categories = torch.tensor([22,28,29,44,61,105,110,121,129,138,142,143,148,23]).reshape(1,-1,1)\n",
    "candidate_spill_categories = torch.tensor([22,29,44,61,105,110,121,129,138,142,143,148,23]).reshape(1,-1,1).to('cuda')\n",
    "floor_cat = torch.tensor([4]).reshape(1,1,1).to('cuda')\n",
    "# water, mirror, rug, sign, river, fountain, swimming_pool, food, lake, tray, screen, plate, glass, painting\n",
    "top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_path, output_path, model_path, model_type=\"dpt_hybrid\", optimize=True):\n",
    "    \"\"\"Run segmentation network\n",
    "\n",
    "    Args:\n",
    "        input_path (str): path to input folder\n",
    "        output_path (str): path to output folder\n",
    "        model_path (str): path to saved model\n",
    "    \"\"\"\n",
    "    print(\"initialize\")\n",
    "\n",
    "    # select device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = 'cpu'\n",
    "    print(\"device: %s\" % device)\n",
    "\n",
    "    net_w = net_h = 480\n",
    "\n",
    "    # load network\n",
    "    if model_type == \"dpt_large\":\n",
    "        model = DPTSegmentationModel(\n",
    "            150,\n",
    "            path=model_path,\n",
    "            backbone=\"vitl16_384\",\n",
    "        )\n",
    "    elif model_type == \"dpt_hybrid\":\n",
    "        model = DPTSegmentationModel(\n",
    "            150,\n",
    "            path=model_path,\n",
    "            backbone=\"vitb_rn50_384\",\n",
    "        )\n",
    "    else:\n",
    "        assert (\n",
    "            False\n",
    "        ), f\"model_type '{model_type}' not implemented, use: --model_type [dpt_large|dpt_hybrid]\"\n",
    "\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize(\n",
    "                net_w,\n",
    "                net_h,\n",
    "                resize_target=None,\n",
    "                keep_aspect_ratio=True,\n",
    "                ensure_multiple_of=32,\n",
    "                resize_method=\"minimal\",\n",
    "                image_interpolation_method=cv2.INTER_CUBIC,\n",
    "            ),\n",
    "            NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            PrepareForNet(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    #if optimize == True and device == torch.device(\"cuda\"):\n",
    "    #    model = model.to(memory_format=torch.channels_last)\n",
    "    #    model = model.half()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # get input\n",
    "    img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "    num_images = len(img_names)\n",
    "\n",
    "    # create output folder\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    print(\"start processing\")\n",
    "\n",
    "    for ind, img_name in enumerate(img_names):\n",
    "\n",
    "        print(\"  processing {} ({}/{})\".format(img_name, ind + 1, num_images))\n",
    "\n",
    "        # input\n",
    "        img = util.io.read_image(img_name)\n",
    "        img_input = transform({\"image\": img})[\"image\"]\n",
    "\n",
    "        # compute\n",
    "        with torch.no_grad():\n",
    "            sample = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
    "            #if optimize == True and device == torch.device(\"cuda\"):\n",
    "            #    sample = sample.to(memory_format=torch.channels_last)\n",
    "            #    sample = sample.half()\n",
    "\n",
    "            out = model.forward(sample)\n",
    "\n",
    "            prediction = torch.nn.functional.interpolate(\n",
    "                out, size=img.shape[:2], mode=\"bicubic\", align_corners=False\n",
    "            )\n",
    "            max_pred = torch.argmax(prediction, dim=1, keepdim=True) + 1\n",
    "            max_pred = max_pred.squeeze().cpu().numpy()\n",
    "            \n",
    "            sorted_k = torch.argsort(prediction, dim=1, descending=True)[:,:top_k] + 1\n",
    "            '''top_k_cats = []\n",
    "            for c in range(10):\n",
    "                cat_plot = cv2.resize(sorted_k[:,c,:,:].float().squeeze().unsqueeze(-1).cpu().numpy(), (70, 40))\n",
    "                cat_plot = cat_plot.astype(np.int32)\n",
    "                top_k_cats.append(cat_plot)\n",
    "            \n",
    "            top_k_cats = np.stack(top_k_cats,axis=0)\n",
    "            top1 = sorted_k[:,0,:,:].float().squeeze().unsqueeze(-1).cpu().numpy()\n",
    "            top2 = sorted_k[:,1,:,:].float().squeeze().unsqueeze(-1).cpu().numpy()\n",
    "            top3 = sorted_k[:,2,:,:].float().squeeze().unsqueeze(-1).cpu().numpy()'''\n",
    "\n",
    "            spill_pix = (sorted_k.reshape(top_k,1,-1) == candidate_spill_categories).any(dim=1).any(dim=0)\n",
    "            floor_pix = (sorted_k[:,:1].reshape(1,-1) == 4).any(dim=0)\n",
    "            candidate_pix = torch.logical_and(spill_pix,floor_pix).reshape(img.shape[:2])\n",
    "            candidate_pix = candidate_pix.long()\n",
    "            seg_mask = candidate_pix.cpu().numpy() + 2\n",
    "            candidate_pix = candidate_pix.cpu().numpy() * 255\n",
    "            \n",
    "\n",
    "        # output\n",
    "        filename = os.path.join(\n",
    "            output_path, os.path.splitext(os.path.basename(img_name))[0]\n",
    "        )\n",
    "        util.io.write_segm_img(filename, img, seg_mask, alpha=0.5)\n",
    "        \n",
    "        img = (img*255).astype(np.uint8)\n",
    "        crops,bboxes = get_spill_crops(img, candidate_pix.astype(np.uint8))\n",
    "        print(len(crops),len(bboxes))\n",
    "        for crop,bbox in zip(crops,bboxes):\n",
    "            resized = cv2.resize(crop, (224, 224)).reshape(1,224,224,3)\n",
    "            inp = resized/255.\n",
    "            outp = spill_classifier(inp)\n",
    "            spill = tf.argmax(outp,axis=1).numpy()[0]\n",
    "            if spill==0:\n",
    "                cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0,255,0), 2)\n",
    "                cv2.putText(img, \"No Spill\", (bbox[0],bbox[1]), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255,0,0), 2)\n",
    "                cv2.putText(img, \"Spill\", (bbox[0],bbox[1]), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 2)\n",
    "        \n",
    "        #cv2.imshow('a',img[:,:,::-1])\n",
    "        #key = cv2.waitKey(0)\n",
    "        #if key == ord('q'):\n",
    "        #    break\n",
    "        cv2.imwrite(filename[:-4]+'2.png',img[:,:,::-1])\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spill_crops(image,spill_seg):\n",
    "    cnts,_ = cv2.findContours(spill_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = []\n",
    "    img_h,img_w,_ = image.shape\n",
    "    img2 = image.copy()\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        bboxes.append((max(x-20,0),max(y-20,0),min(x+w+20,img_w-1),min(y+h+20,img_h-1)))\n",
    "    #    cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (36,255,12), 2)\n",
    "    \n",
    "    no_overlap = True\n",
    "    while no_overlap:\n",
    "        if len(bboxes) < 2:\n",
    "            no_overlap = False\n",
    "            continue\n",
    "        no_overlap = True\n",
    "        bb_ix = -1\n",
    "        while (bb_ix := bb_ix+1) < len(bboxes)-1:\n",
    "            bb1 = bboxes[bb_ix]\n",
    "            bb_ix2 = bb_ix\n",
    "            while (bb_ix2 := bb_ix2+1) < len(bboxes):\n",
    "                bb2 = bboxes[bb_ix2]\n",
    "\n",
    "                x_left = max(bb1[0], bb2[0])\n",
    "                y_top = max(bb1[1], bb2[1])\n",
    "                x_right = min(bb1[2], bb2[2])\n",
    "                y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "                if x_right <= x_left or y_bottom <= y_top:\n",
    "                    continue\n",
    "                else:\n",
    "                    new_bbox = (min(bb1[0],bb2[0]),min(bb1[1],bb2[1]),max(bb1[2],bb2[2]),max(bb1[3],bb2[3]))\n",
    "                    bboxes[bb_ix] = new_bbox\n",
    "                    bb_ix = -1\n",
    "                    del bboxes[bb_ix2]\n",
    "                    no_overlap = False\n",
    "                    break\n",
    "    \n",
    "    crops = []\n",
    "    for bbox in bboxes:\n",
    "        #cv2.rectangle(img2, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (36,255,12), 2)\n",
    "        crops.append(img2[bbox[1]:bbox[3],bbox[0]:bbox[2]])\n",
    "    \n",
    "    #name = str(random.random())\n",
    "    #cv2.imwrite('bbox_images/'+name+'.png', image)\n",
    "    #cv2.imwrite('bbox_images/'+name[:-1]+'z.png', img2)\n",
    "    \n",
    "    return crops,bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize\n",
      "device: cuda\n",
      "start processing\n",
      "  processing input/vlcsnap-2021-08-12-21h45m41s356.png (1/18)\n",
      "2 2\n",
      "  processing input/vlcsnap-2021-08-12-21h47m34s914.png (2/18)\n",
      "4 4\n",
      "  processing input/milk.png (3/18)\n",
      "3 3\n",
      "  processing input/images.jpeg (4/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h48m56s063.png (5/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h48m12s767.png (6/18)\n",
      "3 3\n",
      "  processing input/images (2).jpeg (7/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h47m00s244.png (8/18)\n",
      "5 5\n",
      "  processing input/vlcsnap-2021-08-12-21h47m45s421.png (9/18)\n",
      "4 4\n",
      "  processing input/download (1).jpeg (10/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h49m05s700.png (11/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h48m51s562.png (12/18)\n",
      "2 2\n",
      "  processing input/1627967401592.jpeg (13/18)\n",
      "4 4\n",
      "  processing input/vlcsnap-2021-08-12-21h48m47s313.png (14/18)\n",
      "1 1\n",
      "  processing input/vlcsnap-2021-08-12-21h45m20s326.png (15/18)\n",
      "3 3\n",
      "  processing input/download.jpeg (16/18)\n",
      "1 1\n",
      "  processing input/images (1).jpeg (17/18)\n",
      "2 2\n",
      "  processing input/images (3).jpeg (18/18)\n",
      "1 1\n",
      "finished\n",
      "8.782687\n"
     ]
    }
   ],
   "source": [
    "#spill_points1 = [(10,36),(18,32),(18,33),(18,34),(24,33),(24,34),(24,35),(24,36)]\n",
    "#spill_points1 = [(33,33),(33,34),(34,33),(34,34),(34,35)]\n",
    "spill_points1 = [(35,35),(35,36),(36,35),(36,36)]\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# compute segmentation maps\n",
    "run(\n",
    "    \"input\",\n",
    "    \"output_semseg\",\n",
    "    \"weights/dpt_hybrid-ade20k-53898607.pt\"\n",
    ")\n",
    "\n",
    "print((datetime.datetime.now()-start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "spill_classifier = EfficientNetB0(weights=\"model_best_weights.h5\", include_top=True, input_shape=(height,width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_separators(preds,spill_points,k):\n",
    "    spill_map = preds == -1\n",
    "    spill_map[:,:,:] = False\n",
    "    floor_map = preds == 4\n",
    "    for pnt in spill_points:\n",
    "        floor_map[:10,pnt[0],pnt[1]] = False\n",
    "        spill_map[:10,pnt[0],pnt[1]] = True\n",
    "    \n",
    "    top_k = preds[spill_map]\n",
    "    print(spill_map.shape,top_k.shape)\n",
    "    print(np.unique(top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_top_separators(top_k_cats,spill_points1,3)\n",
    "        \n",
    "        '''if ind == 0:\n",
    "            print(\"-----------TOP 1-------------\")\n",
    "            cat_plot = cv2.resize(top1, (70, 40))\n",
    "            cat_plot = cat_plot.astype(np.int32)\n",
    "            fig, ax = plt.subplots(figsize=(35,20))\n",
    "            sns.heatmap(cat_plot,annot=True,cmap='Blues', fmt='d', ax=ax)\n",
    "\n",
    "            print(\"-----------TOP 2-------------\")\n",
    "            cat_plot = cv2.resize(top2, (70, 40))\n",
    "            cat_plot = cat_plot.astype(np.int32)\n",
    "            fig, ax = plt.subplots(figsize=(35,20))\n",
    "            sns.heatmap(cat_plot,annot=True,cmap='Blues', fmt='d', ax=ax)\n",
    "\n",
    "            print(\"-----------TOP 3-------------\")\n",
    "            cat_plot = cv2.resize(top3, (70, 40))\n",
    "            cat_plot = cat_plot.astype(np.int32)\n",
    "            fig, ax = plt.subplots(figsize=(35,20))\n",
    "            sns.heatmap(cat_plot,annot=True,cmap='Blues', fmt='d', ax=ax)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/petrus/Data/coco/train2017/000000225087.jpg\n"
     ]
    }
   ],
   "source": [
    "coco_imgs = glob.glob(\"/media/petrus/Data/coco/train2017/*\")\n",
    "print(coco_imgs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annots = \"/home/petrus/Downloads/stuff_annotations_trainval2017/annotations/stuff_train2017.json\"\n",
    "file = open(annots)\n",
    "data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'food-other': 6672, 'plastic': 11137, 'table': 16282, 'other': 117266, 'clouds': 9886, 'grass': 22575, 'ground-other': 6252, 'tree': 36466, 'wood': 5053, 'flower': 3259, 'plant-other': 9522, 'wall-concrete': 31481, 'clothes': 27657, 'river': 2313, 'sea': 6598, 'sky-other': 31808, 'floor-other': 8893, 'floor-tile': 6618, 'metal': 22526, 'fence': 11303, 'straw': 1385, 'furniture-other': 17882, 'bush': 9849, 'ceiling-tile': 351, 'pavement': 18311, 'road': 15402, 'wall-stone': 2020, 'window-other': 14209, 'bridge': 1676, 'building-other': 23021, 'house': 6549, 'platform': 2009, 'railroad': 2720, 'roof': 4490, 'floor-stone': 1259, 'dirt': 10163, 'paper': 9521, 'textile-other': 13052, 'cabinet': 7176, 'cardboard': 3787, 'counter': 4589, 'wall-tile': 5290, 'napkin': 1405, 'fog': 2659, 'mountain': 4887, 'railing': 2068, 'gravel': 2613, 'wall-other': 19095, 'floor-marble': 1002, 'wall-wood': 6642, 'window-blind': 2297, 'desk-stuff': 2909, 'floor-wood': 6324, 'mat': 559, 'cage': 2911, 'carpet': 4858, 'ceiling-other': 10546, 'door-stuff': 9475, 'stairs': 2667, 'curtain': 5101, 'rug': 2703, 'shelf': 4589, 'branch': 2813, 'light': 11772, 'mirror-stuff': 3622, 'playingfield': 5251, 'snow': 5114, 'water-other': 2453, 'leaves': 3169, 'pillow': 1986, 'structural-other': 3016, 'rock': 3397, 'hill': 2498, 'towel': 2558, 'sand': 4688, 'wall-brick': 5246, 'skyscraper': 1998, 'banner': 4135, 'net': 1362, 'wall-panel': 2357, 'waterdrops': 121, 'cloth': 3129, 'solid-other': 749, 'blanket': 2598, 'fruit': 2112, 'cupboard': 1004, 'mud': 659, 'tent': 1486, 'stone': 1828, 'vegetable': 2016, 'salad': 477, 'moss': 256})\n"
     ]
    }
   ],
   "source": [
    "cats = data['categories']\n",
    "id_to_name = {}\n",
    "for cat in cats:\n",
    "    id_to_name[cat['id']] = cat['name']\n",
    "    \n",
    "cat_counts = defaultdict(int)\n",
    "for annot in data['annotations']:\n",
    "    cat_counts[id_to_name[annot['category_id']]] += 1\n",
    "\n",
    "print(cat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_cats = ['floor-other','floor-wood','floor-stone','floor-marble','floor-tile','carpet']\n",
    "ground_cats = ['ground-other','playingfield','platform','railroad','pavement','road','gravel','mud','dirt','snow','sand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = {}\n",
    "for img in data['images']:\n",
    "    img_names[img['id']] = img['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_images = {}\n",
    "for annot in data['annotations']:\n",
    "    if id_to_name[annot['category_id']] == 'water-other':\n",
    "        water_images[img_names[annot['image_id']]] = [annot]\n",
    "\n",
    "for annot in data['annotations']:\n",
    "    if img_names[annot['image_id']] in list(water_images.keys()):\n",
    "        water_images[img_names[annot['image_id']]].append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_images = []\n",
    "ground_images = []\n",
    "for fp,img_annots in water_images.items():\n",
    "    for annot in img_annots:\n",
    "        if id_to_name[annot['category_id']] in floor_cats:\n",
    "            floor_images.append(fp)\n",
    "            break\n",
    "    \n",
    "    for annot in img_annots:\n",
    "        if id_to_name[annot['category_id']] in ground_cats:\n",
    "            ground_images.append(fp)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "1415\n"
     ]
    }
   ],
   "source": [
    "print(len(floor_images))\n",
    "print(len(ground_images))\n",
    "\n",
    "for fp in ground_images:\n",
    "    img = cv2.imread(\"/media/petrus/Data/coco/train2017/\"+fp)\n",
    "    cv2.imshow(fp,img)\n",
    "    key = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    if key==27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 3, 'file_name': '000000554625.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000554625.jpg', 'height': 640, 'width': 426, 'date_captured': '2013-11-14 16:03:19', 'flickr_url': 'http://farm5.staticflickr.com/4086/5094162993_8f59d8a473_z.jpg', 'id': 554625}\n",
      "{'segmentation': {'counts': 'Z4l4T:00000O10000O1000000O10000O1000000O1000000O101O0fKoJdNR5\\\\1PKbNP5^1RK`Nn4`1RK`No4_1QK`NP5`1PK`NP5`1PK`NP5`1PK_NQ5a1oJ_NQ5a1oJ_NR5`1nJ`NR5`1nJ_NS5a1mJ_NS5a1mJ_NS5a1mJ^NU5a1kJ_NU5a1kJ_NU5a1kJ_NU5a1kJ^NV5b1jJ^NW5a1iJ_NW5a1iJ_NW5a1iJ^NX5b1hJ^NX5b1hJ^NY5a1gJ^NZ5b1fJ^NZ5b1fJ^NZ5b1fJ^NZ5b1fJ]N[5c1eJ]N\\\\5b1dJ^N\\\\5b1dJ]N]5c1cJ]N]5c1cJ]N]5c1cJ]N]5c1cJ\\\\N^5d1bJ\\\\N^5d1bJ\\\\N^5d1bJ\\\\N^5d1bJ[N_5e1aJ[N_5e1aJ[N_5e1aJ[N_5e1aJ[N_5e1aJ[N_5e1aJ[N_5e1aJZN`5f1`JZN`5f1`JZN`5f1`JZN`5f1`JZN`5f1`JZN`5f1`JZN`5f1`JZN`5f1`JYNa5g1_JYNa5g1_JYNa5g1_JYNa5g1_JYN`5h1`JXN`5h1`JXN_5i1aJWN_5i1aJWN_5i1aJVN_5k1aJUN_5k1aJUN^5l1bJTN^5l1bJTN]5m1cJSN]5m1cJSN\\\\5n1dJRN\\\\5n1dJQN\\\\5P2dJPN\\\\5P2dJPN[5Q2eJoM[5Q2eJoM[5Q2eJoMZ5R2fJnMZ5R2fJoMX5R2hJoMW5Q2iJPNU5Q2kJPNT5P2lJPNS5Q2mJPNR5P2nJQNQ5o1oJRNo4o1QKRNn4n1RKRNm4o1SKRNl4n1TKSNk4m1UKTNi4m1WKTNh4l1XKTNg4m1YKTNf4l1ZKUNe4k1[KUNd4l1\\\\KSNe4m1[KRNf4n1ZKQNf4P2ZKoMg4Q2YKnMg4S2YKlMh4T2XKkMi4U2WKjMi4W2WKhMj4X2VKhMi4Y2WKfMj4Z2VKeMk4[2UKdMk4]2UKbMl4^2TKaMl4`2TK_Mm4a2SK^Mn4b2RK]Mn4d2RK[Mo4e2QKZMo4g2QKXMP5h2PKWMQ5i2oJWMP5j2PKUMQ5k2oJTMR5l2nJSMR5n2nJQMS5o2mJPMS5Q3mJnLT5R3lJmLU5S3kJlLU5U3kJjLV5V3jJiLV5X3jJgLW5Y3iJfLX5Z3hJeLX5\\\\3hJdLX5\\\\3hJdLW5]3iJbLX5^3hJlJK<]5h4hJkJNlNMY1]5Q5hJhJ57S5Q5hJfJ;PO@P1]5Z5hJfJ`0Oh4\\\\5hJdJ`01h4[5hJeJ?0h4\\\\5iJdJ?Oi4]5hJdJ?Oi4]5hJdJ>Oj4^5hJcJ>CV5j5\\\\JcJ>AW5m5[JaJ>AY5n5YJaJ>_O[5P6WJaJ>]O\\\\5S6VJ`J=\\\\O_5T6TJ`J=ZO`5W6SJ_J=XOb5Y6QJ_J<WOd5[6PJmIm0FU5]6nIlIn0EU5`6mIlIl0CY5a6kIlIm0_OZ5f6iIjI\\\\7V6dHkIZ7V6fHeIMD^7g6eHeI^7\\\\6bHdI^7\\\\6bHfIKB_7h6fHhIY7Y6gHgIY7Y6gHgIX7Z6hHfIX7Z6hHfIW7[6iHeIW7[6iHeIV7\\\\6jHdIV7\\\\6jHeIT7\\\\6lHdIT7\\\\6lHcIT7^6lHbIT7^6lHaIT7`6lH`IT7`6lH_IT7b6lH^IT7b6lH^IS7c6mH\\\\IT7d6lH[IT7f6lHZIT7f6lHZIS7g6mHYIS7g6mHXIT7h6lHXIS7i6mHVIT7j6lHWIR7j6nHWIQ7i6oHXIo6i6QIXIn6h6RIYIl6h6TIYIk6g6UIZIi6g6WIZIh6f6XIZIh6f6XI[If6f6ZIZIf6f6ZIYIf6h6ZIXIf6h6ZIWIg6i6YIVIg6k6YITIh6l6XISIh6n6XIQIi6o6WIoHj6R7VInHj6R7VInHj6R7VIoHh6R7XInHh6R7XInHg6S7YImHg6S7YInH8Gk5[7mInH8Gj5\\\\7nImH7Hk5[7nImH6Ik5[7oIkH7Jj5[7oIjH7Li5[7PJjH6Kj5[7PJjH5Mj5Y7QJkH4Lj5Z7RJkH2Ll5Y7RJmH0Jm5Z7SJnHNHo5Z7SJPIKGQ6Z7TJ\\\\Il5d6TJ\\\\Il5d6TJ\\\\Ik5e6UJ[Ik5e6UJlHKKo5Z7VJjHLLn5Z7VJjHLLn5Z7VJjHKMn5Z7WJhHLOl5Y7XJhHLOk5Z7YJgHK0l5Y7YJYIf5h6ZJXIf5h6ZJXIf5h6ZJXIe5i6[JXId5h6\\\\JXIc5i6]JWIc5i6]JWIc5i6]JWIb5j6^JVIb5j6^JVIa5k6_JVI`5j6`JVI_5k6aJUI_5k6aJUI_5k6aJUI^5l6bJTI^5l6bJTI]5m6cJSI]5m6cJTI\\\\5l6dJTI[5m6eJSI[5m6eJSIZ5n6fJRIZ5n6fJSIX5n6hJSIW5m6iJTIV5l6jJTIU5m6kJTIT5l6lJUIR5l6nJUIQ5k6oJVIo4k6QKVIn4j6RKWIm4i6SKWIl4j6TKWIk4i6UKWIj4j6VKVIj4j6VKVIj4j6VKVIi4k6WKUIi4k6WKUIh4l6XKTIh4l6XKTIg4m6YKSIg4n6XKRIh4n6XKRIg4o6YKRIf4n6ZKRIe4o6[KQIe4o6[KQIe4o6[KQId4P7\\\\KQIc4o6]KQIb4P7^KoHc4Q7]KoHb4R7^KoHa4Q7_KPI`4P7`KQI^4P7bKRI\\\\4n6dKSIZ4n6fKSIY4m6gKTIX4l6hKUIV4l6jKUIU4k6kKVIS4k6mKWIQ4i6oKXIo3i6QLXIn3h6RLYIm3g6SLZIk3g6ULZIj3f6VL[Ih3f6XL[Ig3aNUL]74SJf3d6ZL]Id3_NXL^74TJc3c6]L^Ia3]N[L_74UJ`3b6`L_I^3b6bL_I]3a6cL`I\\\\3`6dLaIZ3`6fLaIY3_6gLbIW3_6iLbIV3^6jLcIU3]6kLdIS3]6mLdIR3\\\\6nLeIP3\\\\6PMeIo2[6QMfIm2[6SMWILUNP3d8TMgIk2Y6UMhIi2Y6WMhIh2X6XMiIf2X6ZMiIe2W6[MjId2V6\\\\MkIb2V6^MkIa2U6_MlI_2dM]Mk74bJ^2bM^Mm74bJ\\\\2bM`Ml74cJ[2`MaMn74cJZ2_MbMn74dJX2^MeMn73gJU2[MgMo74jJP2WMmMo73mJm1TMoMP84PKi1oLTNQ83TKd1lLXNQ84WK`1gL]NR83ZK\\\\1eL`NR84]KX1aLdNR84aKS1U5mNoJo0Q5QOdK:\\\\4FhK5Y4KiK3W4MkK0V40lKNT42mKMS43]50000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000O1000000000000000000000000000000000000000000000000000000000000000000_HK75IL64JM53KN42LO31M02OO20M14NL25MJ47KH5:JF6;HE9<FC;>CB>?AA??@Aa0`0]O@d0a0m61O1O1N2O1O1N2O1N2O1N2O1N2O1N2N2O1N2O0O2O1N3N1N2O1N2N2O1N2O1N2O1N2O1N2N2O2M2O1N2O1N2O1N2N2O1N2O1N2O1N2O2M2N2O1N2O1N2O1N2O1N2O1N2N2O2M2O1N2O1N2O1N2N2O1N2O1N2OeK^E00V4h:001N1O1O1O1O1O1N2O1N200O1O1N2O1cGYK`6h4[I[Ke6f4VI_Ki6b4SIaKm6`4nHeKQ7\\\\4kHgKU7\\\\4dHhK]7\\\\4[HgKe7^4SHfKl7_4kGdKV8b51000000O1O2O000O1O2N101N1O100O101N100O2N101O0O101N10bI', 'size': [480, 640]}, 'area': 84156.0, 'iscrowd': 0, 'image_id': 9, 'bbox': [0.0, 11.0, 640.0, 469.0], 'category_id': 121, 'id': 10000000}\n"
     ]
    }
   ],
   "source": [
    "print(data['images'][4])\n",
    "print(data['annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
